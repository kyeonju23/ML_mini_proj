{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6631c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "#     print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f640d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78afacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffle_train_data = [[x,y] for x,y in zip(X_train, y_train)]\n",
    "# suffle_train_data = shuffle(suffle_train_data, random_state = 42)\n",
    "# X_train = [n[0] for n in suffle_train_data]\n",
    "# y_train = [n[1] for n in suffle_train_data]\n",
    "\n",
    "# suffle_test_data = [[x,y] for x,y in zip(X_test, y_test)]\n",
    "# suffle_test_data = shuffle(suffle_test_data, random_state = 42)\n",
    "# X_test = [n[0] for n in suffle_test_data]\n",
    "# y_test = [n[1] for n in suffle_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d9f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train /255\n",
    "y_train = y_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16fb85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8163fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    from functools import partial\n",
    "    DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                          kernel_size = 2, activation = 'selu', \n",
    "                           padding = 'SAME', kernel_initializer = 'lecun_normal')\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3,3), kernel_initializer = 'lecun_normal', activation = 'selu',\n",
    "                                 input_shape = [28, 28, 1]))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(DefaultConv2D(filters = 32))\n",
    "#     model.add(DefaultConv2D(filters = 32))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(DefaultConv2D(filters = 64))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(DefaultConv2D(filters = 64))\n",
    "#     model.add(DefaultConv2D(filters = 64))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(DefaultConv2D(filters = 128))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(DefaultConv2D(filters = 128))\n",
    "#     model.add(DefaultConv2D(filters = 128))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "\n",
    "#     model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Flatten())\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(64, kernel_initializer = 'lecun_normal', activation = 'selu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(32, kernel_initializer = 'lecun_normal', activation = 'selu'))\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d74c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folding(num_epochs):\n",
    "    early_stop_patiences = 5\n",
    "    k = 10\n",
    "    num_val = len(X_train) // k\n",
    "    all_scores = []\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    #early stopping\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = early_stop_patiences,\n",
    "                                                     restore_best_weights = True,\n",
    "                                                     monitor = 'val_accuracy',\n",
    "                                                     mode = 'auto')\n",
    "\n",
    "    #learning_rate down\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 10)\n",
    "    \n",
    "    for i in range(k):\n",
    "        #callback\n",
    "        checkpoint_cb = keras.callbacks.ModelCheckpoint(f\"my_proj01_model_{i}.h5\",\n",
    "                                                   save_best_only = True)\n",
    "        print('processing fold #', i)\n",
    "\n",
    "        X_val = X_train[i * num_val: (i + 1) * num_val]\n",
    "        y_val = y_train[i * num_val: (i + 1) * num_val]\n",
    "        X_train_part = np.concatenate(\n",
    "            [X_train[:i * num_val],\n",
    "            X_train[(i + 1) * num_val:]],\n",
    "            axis = 0)\n",
    "        y_train_part = np.concatenate(\n",
    "            [y_train[:i * num_val],\n",
    "            y_train[(i + 1) * num_val:]],\n",
    "            axis = 0)\n",
    "\n",
    "        model = make_model()\n",
    "        model.fit(X_train_part, y_train_part,\n",
    "                 epochs = num_epochs, validation_data = (X_val, y_val),\n",
    "                 batch_size = 8,\n",
    "                 callbacks = [early_stopping_cb, checkpoint_cb])\n",
    "        \n",
    "        model = keras.models.load_model(f\"my_proj01_model_{i}.h5\")\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose = 0)\n",
    "        all_scores.append(val_accuracy)\n",
    "        print(f\"{val_accuracy}\\n\")\n",
    "    print(all_scores)\n",
    "    print(f\"score : {np.mean(all_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a89dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:850 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:840 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:833 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:790 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:230 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (8, 28, 28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19616/3471893883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mk_folding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19616/1561360118.py\u001b[0m in \u001b[0;36mk_folding\u001b[1;34m(num_epochs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         model.fit(X_train_part, y_train_part,\n\u001b[0m\u001b[0;32m     38\u001b[0m                  \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                  \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 _r=1):\n\u001b[0;32m   1177\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:850 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:840 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:833 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:790 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\kyeon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:230 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (8, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "k_folding(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make2_model():\n",
    "    from functools import partial\n",
    "    DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=2, strides=1,\n",
    "                            padding=\"SAME\", use_bias=False)\n",
    "\n",
    "    class ResidualUnit(keras.layers.Layer):\n",
    "        def __init__(self, filters, strides=1, activation=\"selu\", **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.activation = keras.activations.get(activation)\n",
    "            self.main_layers = [\n",
    "                DefaultConv2D(filters, strides=strides),\n",
    "                keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                DefaultConv2D(filters),\n",
    "                keras.layers.BatchNormalization()]\n",
    "            self.skip_layers = []\n",
    "            if strides > 1:\n",
    "                self.skip_layers = [\n",
    "                    DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                    keras.layers.BatchNormalization()]\n",
    "\n",
    "        def call(self, inputs):\n",
    "            Z = inputs\n",
    "            for layer in self.main_layers:\n",
    "                Z = layer(Z)\n",
    "            skip_Z = inputs\n",
    "            for layer in self.skip_layers:\n",
    "                skip_Z = layer(skip_Z)\n",
    "            return self.activation(Z + skip_Z)\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(DefaultConv2D(64, kernel_size=2, strides=1,\n",
    "                            input_shape=[28, 28, 1]))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"selu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "    prev_filters = 8\n",
    "    for filters in [64] * 2 + [128] * 2 + [256] * 2 + [512] * 2:\n",
    "        strides = 1 if filters == prev_filters else 2\n",
    "        model.add(ResidualUnit(filters, strides=strides))\n",
    "        prev_filters = filters\n",
    "    model.add(keras.layers.GlobalAvgPool2D())\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a50991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folding(num_epochs):\n",
    "    early_stop_patiences = 5\n",
    "    k = 10\n",
    "    num_val = len(X_train) // k\n",
    "    all_scores = []\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    #early stopping\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = early_stop_patiences,\n",
    "                                                     restore_best_weights = True,\n",
    "                                                     monitor = 'val_accuracy',\n",
    "                                                     mode = 'auto')\n",
    "\n",
    "    #learning_rate down\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 10)\n",
    "    \n",
    "    for i in range(k):\n",
    "        #callback\n",
    "        checkpoint_cb = keras.callbacks.ModelCheckpoint(f\"my_proj01_model_{i}.h5\",\n",
    "                                                   save_best_only = True)\n",
    "        print('processing fold #', i)\n",
    "\n",
    "        X_val = X_train[i * num_val: (i + 1) * num_val]\n",
    "        y_val = y_train[i * num_val: (i + 1) * num_val]\n",
    "        X_train_part = np.concatenate(\n",
    "            [X_train[:i * num_val],\n",
    "            X_train[(i + 1) * num_val:]],\n",
    "            axis = 0)\n",
    "        y_train_part = np.concatenate(\n",
    "            [y_train[:i * num_val],\n",
    "            y_train[(i + 1) * num_val:]],\n",
    "            axis = 0)\n",
    "\n",
    "        model = make2_model()\n",
    "        model.fit(X_train_part, y_train_part,\n",
    "                 epochs = num_epochs, validation_data = (X_val, y_val),\n",
    "                 batch_size = 64,\n",
    "                 callbacks = [early_stopping_cb, checkpoint_cb])\n",
    "        \n",
    "        model = keras.models.load_model(f\"my_proj01_model_{i}.h5\")\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose = 0)\n",
    "        all_scores.append(val_accuracy)\n",
    "        print(f\"{val_accuracy}\\n\")\n",
    "    print(all_scores)\n",
    "    print(f\"score : {np.mean(all_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folding(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7f450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_run(num_epochs, num_batch_size):\n",
    "#     early_stop_patiences = 15\n",
    "#     keras.backend.clear_session()\n",
    "#     np.random.seed(42)\n",
    "#     tf.random.set_seed(42)\n",
    "    \n",
    "#     model = make_model()\n",
    "#     model.summary()\n",
    "    \n",
    "#     #callback\n",
    "#     checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\",\n",
    "#                                                    save_best_only = True)\n",
    "#     #early stopping\n",
    "#     early_stopping_cb = keras.callbacks.EarlyStopping(patience = early_stop_patiences,\n",
    "#                                                      restore_best_weights = True)\n",
    "    \n",
    "#     #learning_rate down\n",
    "#     lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 5)\n",
    "    \n",
    "#     model.fit(X_train, y_train, epochs = num_epochs, batch_size = 2 ** num_batch_size,\n",
    "#               validation_data = (X_valid, y_valid),\n",
    "#              callbacks = [lr_scheduler, early_stopping_cb, checkpoint_cb])\n",
    "    \n",
    "#     model = keras.models.load_model(\"my_mnist_model.h5\")\n",
    "#     test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "#     print(test_acc)\n",
    "#     print(early_stopping_cb.stopped_epoch - early_stop_patiences + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca8c8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_run(500, 7)\n",
    "# #model_run(epoch 수, 2의 n제곱)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a91b58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.9054999947547913\n",
    "#0.8917999863624573\n",
    "#500 epoch, 1024 batch 0.9107999801635742\n",
    "\n",
    "#selu\n",
    "#500 epoch, 1024 batch 0.8946999907493591\n",
    "#500 epoch, 1024 batch 0.8986999988555908\n",
    "\n",
    "#500, 256 0.9146000146865845\n",
    "\n",
    "#0.9126999974250793\n",
    "#0.9232000112533569\n",
    "#0.929099977016449(32 32 32 64 64 64 128 128 128)\n",
    "#0.9325000047683716(64 32 64 64 128 128)\n",
    "#0.9358999729156494(64 32 64 64 128 128) batch 2**7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344f9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make2_model():\n",
    "#     from functools import partial\n",
    "#     DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "#                           kernel_size = 2, activation = 'selu', \n",
    "#                            padding = 'SAME', kernel_initializer = 'lecun_normal')\n",
    "    \n",
    "#     model = keras.models.Sequential()\n",
    "#     model.add(keras.layers.Conv2D(64, (3,3), kernel_initializer = 'lecun_normal', activation = 'selu',\n",
    "#                                  input_shape = [28, 28, 1]))\n",
    "#     model.add(keras.layers.Dropout(rate = 0.5))\n",
    "#     model.add(DefaultConv2D(filters = 64))\n",
    "# #     model.add(DefaultConv2D(filters = 32))\n",
    "#     model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(DefaultConv2D(filters = 64))\n",
    "#     model.add(DefaultConv2D(filters = 64))\n",
    "# #     model.add(DefaultConv2D(filters = 64))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "#     model.add(DefaultConv2D(filters = 128))\n",
    "#     model.add(DefaultConv2D(filters = 128))\n",
    "# #     model.add(DefaultConv2D(filters = 128))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "\n",
    "# #     model.add(keras.layers.GlobalAveragePooling2D())\n",
    "#     model.add(keras.layers.Flatten())\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.Dense(64, kernel_initializer = 'lecun_normal', activation = 'selu'))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.Dense(32, kernel_initializer = 'lecun_normal', activation = 'selu'))\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "#     model.compile(optimizer='adam',\n",
    "#              loss='categorical_crossentropy',\n",
    "#              metrics = ['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452410e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model2_run(num_epochs, num_batch_size):\n",
    "#     early_stop_patiences = 15\n",
    "#     keras.backend.clear_session()\n",
    "#     np.random.seed(42)\n",
    "#     tf.random.set_seed(42)\n",
    "    \n",
    "#     model = make2_model()\n",
    "#     model.summary()\n",
    "    \n",
    "#     #callback\n",
    "#     checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model_2.h5\",\n",
    "#                                                    save_best_only = True)\n",
    "#     #early stopping\n",
    "#     early_stopping_cb = keras.callbacks.EarlyStopping(patience = early_stop_patiences,\n",
    "#                                                      restore_best_weights = True)\n",
    "    \n",
    "#     #learning_rate down\n",
    "#     lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 5)\n",
    "    \n",
    "#     model.fit(X_train, y_train, epochs = num_epochs, batch_size = 2 ** num_batch_size,\n",
    "#               validation_data = (X_valid, y_valid),\n",
    "#              callbacks = [lr_scheduler, early_stopping_cb, checkpoint_cb])\n",
    "    \n",
    "#     model = keras.models.load_model(\"my_mnist_model_2.h5\")\n",
    "#     test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "#     print(test_acc)\n",
    "#     print(early_stopping_cb.stopped_epoch - early_stop_patiences + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e0c6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2_run(500, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2790b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make3_model():\n",
    "#     from functools import partial\n",
    "#     DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "#                           kernel_size = 3, activation = 'selu', \n",
    "#                            padding = 'SAME', kernel_initializer = 'lecun_normal')\n",
    "    \n",
    "#     model = keras.models.Sequential()\n",
    "#     model.add(keras.layers.Conv2D(128, (2,2), kernel_initializer = 'lecun_normal', activation = 'selu',\n",
    "#                                  input_shape = (28, 28, 1)))\n",
    "#     model.add(DefaultConv2D(filters = 128))\n",
    "#     model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(DefaultConv2D(filters = 256))\n",
    "#     model.add(DefaultConv2D(filters = 256))\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "#     model.add(DefaultConv2D(filters = 512))\n",
    "#     model.add(DefaultConv2D(filters = 512))\n",
    "# #     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# #     model.add(keras.layers.GlobalAveragePooling2D())\n",
    "#     model.add(keras.layers.Flatten())\n",
    "#     model.add(keras.layers.Dense(256, kernel_initializer = 'lecun_normal', activation = 'selu'))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.Dense(128, kernel_initializer = 'lecun_normal', activation = 'selu'))\n",
    "#     model.add(keras.layers.Dropout(rate=0.5))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "#     model.compile(optimizer='adam',\n",
    "#              loss='categorical_crossentropy',\n",
    "#              metrics = ['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5df291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model3_run(num_epochs, num_batch_size):\n",
    "#     keras.backend.clear_session()\n",
    "#     np.random.seed(42)\n",
    "#     tf.random.set_seed(42)\n",
    "    \n",
    "#     model = make3_model()\n",
    "    \n",
    "#     #callback\n",
    "#     checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model_3.h5\",\n",
    "#                                                    save_best_only = True)\n",
    "#     #early stopping\n",
    "#     early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20,\n",
    "#                                                      restore_best_weights = True)\n",
    "    \n",
    "#     #learning_rate down\n",
    "#     lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 5)\n",
    "    \n",
    "#     model.fit(X_train, y_train, epochs = num_epochs, batch_size = num_batch_size,\n",
    "#               validation_data = (X_valid, y_valid),\n",
    "#              callbacks = [lr_scheduler, early_stopping_cb, checkpoint_cb])\n",
    "    \n",
    "#     model = keras.models.load_model(\"my_mnist_model_3.h5\")\n",
    "#     test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "#     print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ebe59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3_run(500, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c734c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
